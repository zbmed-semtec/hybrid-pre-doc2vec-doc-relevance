{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline as pipe\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('code/embeddings/')\n",
    "sys.path.append(\"code/counting_table\")\n",
    "\n",
    "import create_model as cm\n",
    "import calculate_sim as cs\n",
    "import generate_counting_table as ct\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "## Step 1:\n",
    "\n",
    "Generate the hyperparameters to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_d2v = {\n",
    "    \"dm\": [1, 0],\n",
    "    \"vector_size\": [256, 512], \n",
    "    \"window\": [5, 9], \n",
    "    \"min_count\": [5], \n",
    "    \"epochs\": [10], \n",
    "    \"workers\": [6]}\n",
    "\n",
    "params_d2v = {\n",
    "    \"dm\": [1, 0],\n",
    "    \"vector_size\": [256], \n",
    "    \"window\": [9], \n",
    "    \"min_count\": [5], \n",
    "    \"epochs\": [10], \n",
    "    \"workers\": [6]}\n",
    "\n",
    "hp_df = pipe.generate_hyperparameters(params_d2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "\n",
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_tokens = \"../data_full/RELISH/RELISH_tokens.tsv\"\n",
    "#input_relevance_matrix = \"../data_full/RELISH/RELISH_relevance_matrix.tsv\"\n",
    "\n",
    "input_tokens = \"../data_full/TREC/TREC_tokens.tsv\"\n",
    "input_relevance_matrix = \"../data_full/TREC/TREC_relevance_matrix.tsv\"\n",
    "\n",
    "relevance_matrix = cs.load_relevance_matrix(input_relevance_matrix)\n",
    "pmid, join_text = cm.load_tokens(input_tokens)\n",
    "tagged_data = cm.generate_TaggedDocument(pmid, join_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:\n",
    "\n",
    "Execute pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting row 0:\n",
      "\tGenerate and train the model.\n",
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n",
      "--- Time to train: 60.17 seconds\n",
      "\tFill the relevance matrix.\n",
      "Process at 0%\n",
      "Process at 5%\n",
      "Process at 10%\n",
      "Process at 15%\n",
      "Process at 20%\n",
      "Process at 25%\n",
      "Process at 30%\n",
      "Process at 35%\n",
      "Process at 40%\n",
      "Process at 45%\n",
      "Process at 50%\n",
      "Process at 55%\n",
      "Process at 60%\n",
      "Process at 65%\n",
      "Process at 70%\n",
      "Process at 75%\n",
      "Process at 80%\n",
      "Process at 85%\n",
      "Process at 90%\n",
      "Process at 95%\n",
      "Process at 100%\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Relevance Assessment'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Relevance Assessment'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/hybrid-dictionary-ner-doc2vec-doc-relevance/testing/hyperparameter_optimization/pipeline_notebook.ipynb Celda 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B193.196.29.87/home/ubuntu/hybrid-dictionary-ner-doc2vec-doc-relevance/testing/hyperparameter_optimization/pipeline_notebook.ipynb#ch0000015vscode-remote?line=0'>1</a>\u001b[0m pipe\u001b[39m.\u001b[39;49mexecute_optimization(hp_df, tagged_data, relevance_matrix, \u001b[39m\"\u001b[39;49m\u001b[39mTREC\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtest_3_trec\u001b[39;49m\u001b[39m\"\u001b[39;49m, load_table\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, save_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/hybrid-dictionary-ner-doc2vec-doc-relevance/testing/hyperparameter_optimization/pipeline.py:59\u001b[0m, in \u001b[0;36mexecute_optimization\u001b[0;34m(hp_df, tagged_data, relevance_matrix, dataset, output_dir, load_table, save_model, custom_relish)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m custom_relish:\n\u001b[0;32m---> 59\u001b[0m         counting_table \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39mcreate_counting_table(relevance_matrix_row, dataset \u001b[39m=\u001b[39m dataset)\n\u001b[1;32m     60\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m         counting_table \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39mcustom_counting_table_relish(relevance_matrix_row, dataset \u001b[39m=\u001b[39m dataset)\n",
      "File \u001b[0;32m~/hybrid-dictionary-ner-doc2vec-doc-relevance/code/counting_table/generate_counting_table.py:137\u001b[0m, in \u001b[0;36mcreate_counting_table\u001b[0;34m(data, dataset)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m counting_df\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m    136\u001b[0m     interval \u001b[39m=\u001b[39m row[\u001b[39m\"\u001b[39m\u001b[39mCosine Interval\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 137\u001b[0m     interval_counts \u001b[39m=\u001b[39m count_entries(data, interval)\n\u001b[1;32m    139\u001b[0m     counting_df\u001b[39m.\u001b[39mat[i, \u001b[39m\"\u001b[39m\u001b[39mAs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m interval_counts[\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    140\u001b[0m     counting_df\u001b[39m.\u001b[39mat[i, \u001b[39m\"\u001b[39m\u001b[39mBs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m interval_counts[\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/hybrid-dictionary-ner-doc2vec-doc-relevance/code/counting_table/generate_counting_table.py:94\u001b[0m, in \u001b[0;36mcount_entries\u001b[0;34m(data, interval, dataset)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39mCounts the number of Relevance Assessment for a given value of Cosine\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39mSimilarity.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m    Dictionary containing the counts for each Relevance Assessment\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRELISH\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     filtered_df \u001b[39m=\u001b[39m data[data[\u001b[39m\"\u001b[39;49m\u001b[39mCosine Similarity\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39;49m interval][\u001b[39m\"\u001b[39;49m\u001b[39mRelevance Assessment\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     95\u001b[0m     counter \u001b[39m=\u001b[39m {\u001b[39m0\u001b[39m: \u001b[39msum\u001b[39m(filtered_df \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m: \u001b[39msum\u001b[39m(filtered_df \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m2\u001b[39m: \u001b[39msum\u001b[39m(filtered_df \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m)}\n\u001b[1;32m     97\u001b[0m \u001b[39melif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTREC\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Relevance Assessment'"
     ]
    }
   ],
   "source": [
    "pipe.execute_optimization(hp_df, tagged_data, relevance_matrix, \"TREC\", \"test_3_trec\", load_table=False, save_model=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.expanduser(\"~/hybrid-dictionary-ner-doc2vec-doc-relevance/code/embeddings/\"))\n",
    "sys.path.append(os.path.expanduser(\"~/hybrid-dictionary-ner-doc2vec-doc-relevance/code/tendency_analysis/\"))\n",
    "\n",
    "import create_model as cm\n",
    "import calculate_sim as cs\n",
    "import counting_table as ct\n",
    "import ROC_curve as ROC\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "os.chdir(os.path.expanduser('~/hybrid-dictionary-ner-doc2vec-doc-relevance/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hyperparameters(params):\n",
    "    try:\n",
    "        from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "        param_grid = ParameterGrid(params)\n",
    "        df_hp = pd.DataFrame.from_dict(param_grid)\n",
    "\n",
    "        return df_hp\n",
    "    except:\n",
    "        import itertools\n",
    "\n",
    "        keys, values = zip(*params.items())\n",
    "        df_hp = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "        return df_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "## Step 1:\n",
    "\n",
    "Generate the hyperparameters to test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dm</th>\n",
       "      <th>epochs</th>\n",
       "      <th>min_count</th>\n",
       "      <th>vector_size</th>\n",
       "      <th>window</th>\n",
       "      <th>workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dm  epochs  min_count  vector_size  window  workers\n",
       "0   1       5          5          256       5        8\n",
       "1   1       5          5          256       6        8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_d2v = {\n",
    "    \"dm\": [1],\n",
    "    \"vector_size\": [256], \n",
    "    \"window\": [5, 6], \n",
    "    \"min_count\": [5], \n",
    "    \"epochs\": [5], \n",
    "    \"workers\": [8]}\n",
    "\n",
    "hp_df = generate_hyperparameters(params_d2v)\n",
    "hp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:\n",
    "\n",
    "Load the data:\n",
    "\n",
    "1. Tokens: a .TSV file generated after the preprocessing step.\n",
    "\n",
    "2. Relevance matrix: for relish, required 3 columns \"PMID1\", \"PMID2\" and \"relevance\". For TREC, required 3 columns \"PMID1\", \"PMID2\" and \"Group\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths: \n",
    "#input_tokens = \"../data_full/RELISH/RELISH_tokens.tsv\"\n",
    "#input_relevance_matrix = \"../data_full/RELISH/RELISH_relevance_matrix.tsv\"\n",
    "input_tokens = \"../data_full/TREC/TREC_tokens.tsv\"\n",
    "input_relevance_matrix = \"../data_full/TREC/TREC_relevance_matrix.tsv\"\n",
    "\n",
    "# Load the relevance matrix and the tokens:\n",
    "relevance_matrix = cs.load_relevance_matrix(input_relevance_matrix)\n",
    "pmid, join_text = cm.load_tokens(input_tokens)\n",
    "\n",
    "# Generate the training documents:\n",
    "tagged_data = cm.generate_TaggedDocument(pmid, join_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:\n",
    "\n",
    "Execute pipeline. It is divided in these processes:\n",
    "\n",
    "1. Generate a folder to contain all the variables or figures for a given hyperparameter search.\n",
    "\n",
    "2. Loop through every column of the hyperparameter DataFrame. For each combination of hyperparameters execute:\n",
    "\n",
    "    2.1. Generate the doc2vec model. Optionally, store it in the output directory or load it.\n",
    "\n",
    "    2.2. Fill the relevance matrix with the trained model. It is recommended to use the multiprocessing function in order to accelerate the process. Optionally, store the filled relevance matrix or load it.\n",
    "\n",
    "    2.3. Generate the counting table from the filled relevance matrix. Optionally, store the filled counting table or load it.\n",
    "\n",
    "    2.4. Generate the ROC curve and calculate the area under its curve (AUC). The AUC value is stored in the hyperparameter DataFrame and stored in the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting row 0:\n",
      "\tGenerate and train the model.\n",
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "--- Time to train: 35.64 seconds\n",
      "\tSave the model.\n",
      "\tFill the relevance matrix.\n",
      "\tGenerating the counting table.\n",
      "\tSaving the counting table.\n",
      "\tPlotting the ROC curve.\n",
      "Starting row 1:\n",
      "\tGenerate and train the model.\n",
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "--- Time to train: 34.00 seconds\n",
      "\tSave the model.\n",
      "\tFill the relevance matrix.\n",
      "\tGenerating the counting table.\n",
      "\tSaving the counting table.\n",
      "\tPlotting the ROC curve.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dm</th>\n",
       "      <th>epochs</th>\n",
       "      <th>min_count</th>\n",
       "      <th>vector_size</th>\n",
       "      <th>window</th>\n",
       "      <th>workers</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.601351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.598169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dm  epochs  min_count  vector_size  window  workers       AUC\n",
       "0   1       5          5          256       5        8  0.601351\n",
       "1   1       5          5          256       6        8  0.598169"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def execute_optimization(hp_df: pd.DataFrame, \n",
    "        tagged_data: TaggedDocument, \n",
    "        relevance_matrix: pd.DataFrame, \n",
    "        dataset: str, \n",
    "        output_dir: str, \n",
    "        load_model: bool = False,\n",
    "        save_model: bool = False, \n",
    "        load_rel_matrix: bool = False,\n",
    "        save_rel_matrix: bool = False,\n",
    "        load_counting_table: bool = False,\n",
    "        save_counting_table: bool = False):\n",
    "\n",
    "    output_dir = f\"testing/hyperparameter_optimization/runs/{output_dir}\"\n",
    "    if not os.path.exists(output_dir): os.mkdir(output_dir)\n",
    "\n",
    "    hp_df_path = output_dir + \"/hp_df.tsv\"\n",
    "    hp_df.to_csv(hp_df_path, sep = \"\\t\")\n",
    "\n",
    "    hp_df[\"AUC\"] = 0\n",
    "    for i, row in hp_df.iterrows():\n",
    "        print(f\"Starting row {i}:\")\n",
    "        params = row.to_dict()\n",
    "        del params[\"AUC\"]\n",
    "\n",
    "        relevance_matrix_row = relevance_matrix.copy(deep = True)\n",
    "\n",
    "        # Models\n",
    "        print(f\"\\tGenerate and train the model.\")\n",
    "        model_path = output_dir + f\"/model_{i}.model\"\n",
    "        if load_model and os.path.exists(model_path):\n",
    "            model = cs.load_d2v_model(model_path)\n",
    "        else:\n",
    "            model = cm.generate_doc2vec_model(tagged_data, params)\n",
    "            cm.train_doc2vec_model(model, tagged_data, time_train = True)\n",
    "\n",
    "            # We shouldn't save each model, it would take too much disk space\n",
    "            if save_model:\n",
    "                print(f\"\\tSave the model.\")\n",
    "                cm.save_doc2vec_model(model, output_dir + f\"/model_{i}.model\")\n",
    "\n",
    "        # Relevance Matrix\n",
    "        print(f\"\\tFill the relevance matrix.\")\n",
    "        rel_matrix_path = output_dir + f\"/relevance_matrix_{i}.tsv\"\n",
    "        if load_rel_matrix and os.path.exists(rel_matrix_path):\n",
    "            relevance_matrix_row = cm.load_relevance_matrix(rel_matrix_path)\n",
    "        else:\n",
    "            cs.fill_relevance_matrix_multiprocess(relevance_matrix_row, model)\n",
    "            if save_rel_matrix:\n",
    "                print(f\"\\tSaving the relevance matrix.\")\n",
    "                cs.save_rel_matrix(relevance_matrix_row, rel_matrix_path)\n",
    "\n",
    "        # Counting Table\n",
    "        print(f\"\\tGenerating the counting table.\")\n",
    "        counting_table_path = output_dir + f\"/counting_table_{i}.tsv\"\n",
    "        if load_counting_table and os.path.exists(counting_table_path):\n",
    "            counting_table = pd.read_csv(counting_table_path, sep = \"\\t\")\n",
    "        else:\n",
    "            counting_table = ct.hp_create_counting_table(relevance_matrix_row, dataset = dataset)\n",
    "            if save_counting_table:\n",
    "                print(f\"\\tSaving the counting table.\")\n",
    "                ct.save_table(counting_table, counting_table_path)\n",
    "\n",
    "        # Measure and save ROC\n",
    "        print(f\"\\tPlotting the ROC curve.\")\n",
    "        ROC_path = output_dir + f\"/ROC_{i}.png\"\n",
    "        ROC.generate_roc_values(counting_table, dataset = dataset)\n",
    "        ROC.draw_roc_curve(counting_table, draw_auc = True, show_figure = False, output_path = ROC_path)\n",
    "\n",
    "        hp_df.at[i, \"AUC\"] = ROC.calculate_auc(counting_table)\n",
    "        hp_df.to_csv(hp_df_path, sep = \"\\t\")\n",
    "    \n",
    "    return hp_df\n",
    "\n",
    "execute_optimization(hp_df, tagged_data, relevance_matrix, dataset = \"TREC\", output_dir = \"Last_TREC_test\", save_model=True, load_model=True, save_counting_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Information\n",
    "\n",
    "This pipeline is still under development. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
